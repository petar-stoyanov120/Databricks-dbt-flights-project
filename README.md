# âœˆï¸ End-to-End Flight Data Engineering Pipeline  
**Databricks â€¢ dbt â€¢ Medallion Architecture**

## ğŸ“Œ Project Overview
This project demonstrates an **automated, incremental data engineering pipeline** built on **Databricks**, following the **Medallion Architecture**.

The pipeline processes raw flight booking data through **Bronze, Silver, and Gold layers**, culminating in a **production-ready Gold layer** modeled as a **Star Schema** and consumed through **dbt Cloud**.

---

## ğŸ—ï¸ High-Level Architecture
The data flows through the following stages:

1. **Raw Zone**
   - CSV files landed in **Databricks Volumes**

2. **Bronze Layer**
   - Incremental ingestion using **Databricks Autoloader**

3. **Silver Layer**
   - Data cleaning and quality enforcement via  
     **Lakeflow Declarative Pipelines (DLT)**

4. **Gold Layer**
   - Dynamic dimensional modeling (**Star Schema**)
   - Implements **Slowly Changing Dimensions (SCD Type 1)**

5. **Analytics Layer**
   - Business logic transformations managed in **dbt Cloud**

---

## ğŸ§° Technical Stack

### Platform
- **Databricks (Free Edition)**

### Storage & Governance
- **Unity Catalog**
- **Delta Lake**
- **Databricks Volumes**

### Processing
- **PySpark**
- **Spark Structured Streaming**

### Orchestration & Workflow
- **Databricks Jobs** (Control Flow & Looping)
- **Lakeflow**

### Transformation & Modeling
- **dbt Cloud**
- **Databricks SQL Warehouse**

---

## ğŸ§  Key Engineering Concepts Demonstrated

### ğŸ”¹ Medallion Architecture
Structured progression of data:
- **Bronze** â†’ Raw, incremental ingestion  
- **Silver** â†’ Cleaned, validated datasets  
- **Gold** â†’ Business-ready dimensional models  

### ğŸ”¹ Incremental Processing
- Efficient ingestion using **Databricks Autoloader**
- Processes data in an **â€œavailable-onceâ€** pattern

### ğŸ”¹ Dynamic Pipeline Design
- Reusable **Python builders** for facts and dimensions
- Parameter-driven pipelines instead of static notebooks

### ğŸ”¹ Data Quality Enforcement
- **DLT Expectations** to:
  - Drop malformed records
  - Flag data quality issues early

### ğŸ”¹ SCD Type 1
- Dynamic handling of dimension updates
- Ensures a **single version of the truth**

---

## ğŸš€ Future Improvements
- âœ… Add **dbt Tests** for schema & referential integrity
- âš¡ Explore **Liquid Clustering** or **Partition Pruning** in Gold
- ğŸ”„ Integrate **CI/CD pipelines** for dbt deployments

---

## ğŸ“‚ Repository Structure (Optional)
```text
.
â”œâ”€â”€ bronze/
â”œâ”€â”€ silver/
â”œâ”€â”€ gold/
â”œâ”€â”€ dbt/
â”œâ”€â”€ jobs/
â””â”€â”€ README.md
